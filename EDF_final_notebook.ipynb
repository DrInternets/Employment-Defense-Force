{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDF Project Notebook\n",
    "\n",
    "## Overview and Motivation\n",
    "\n",
    "The goal of this project was to analyze several major job posting boards in order to determine which are useful. We hoped to analyze the results of job searches not necessarily to find a single best job posting board, rather, we hoped to find the best job posting board for different situations.\n",
    "\n",
    "## Initial Question\n",
    "\n",
    "Initially we were hoping to analyze the descriptions of jobs. Unfortunately during this process we were unable to retrieve the descriptions from jobs. This is due to a few reasons partly that some job posting boards are deliberately hiding their data and some others link back the employers own site for applications. \n",
    "\n",
    "### Data Collection\n",
    "\n",
    "We collected data from four different job sites: LinkedIn, Monster, Indeed, and Glassdoor. From LinkedIn and Monster we scraped data from their standard search interface. From Indeed we used their api. The only available data from glass door is aggregated data from the Glassdoor api so it contains different information from the other data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import re\n",
    "from bokeh.charts import Bar, output_file, show\n",
    "from indeed import IndeedClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'Developer'\n",
    "LOCATION = '' # location should be full state name (e.g. Texas) or nothing for all states\n",
    "N_RESULTS = 1000\n",
    "DATA_FILE_NAME = 'monster_results_1000.json'\n",
    "\n",
    "def get_html_page(page):\n",
    "    request = 'https://www.monster.com/jobs/search/?q='\n",
    "    query = QUERY.replace(' ', '-')\n",
    "    request += query\n",
    "    request += '&where='\n",
    "    request += LOCATION\n",
    "    request += '&page='\n",
    "    request += str(page)\n",
    "    \n",
    "    return requests.get(request)\n",
    "\n",
    "def get_page_results(page):\n",
    "    r = get_html_page(page)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    results = soup.find_all('script', {'type' : 'application/ld+json'}) # Results come in script tag\n",
    "    results.pop(0) # Remove search info from results\n",
    "    return results\n",
    "\n",
    "def get_results():\n",
    "    results = []\n",
    "    current_page = 1\n",
    "    # Add results page by page\n",
    "    while len(results) < N_RESULTS:\n",
    "        results += get_page_results(current_page)\n",
    "        current_page += 1\n",
    "    # Remove extra results from end\n",
    "    while len(results) > N_RESULTS:\n",
    "        results.pop(-1)\n",
    "    return results\n",
    "\n",
    "def make_json(results):\n",
    "    json_string = '{ \"results\" : [' # Open json\n",
    "    # Write results\n",
    "    for result in results:\n",
    "        result_text = result.string # Get result string\n",
    "        # Clean out extra spaces and new lines\n",
    "        result_text = result_text.replace('\\r\\n', '')\n",
    "        result_text = result_text.replace('  ', ' ')\n",
    "        result_text = result_text.replace('  ', ' ')\n",
    "        result_text = result_text.replace('  ', ' ')\n",
    "        result_text = result_text.replace('  ', ' ')\n",
    "        json_string += result_text # Append to json\n",
    "        # Add ',' if not last element\n",
    "        if result != results[-1]:\n",
    "            json_string += ','\n",
    "    json_string += ']}' # Close json\n",
    "    # Prettify\n",
    "    json_string = json.loads(json_string)\n",
    "    json_string = json.dumps(json_string, sort_keys=True, indent=4)\n",
    "    return json_string\n",
    "    \n",
    "results = get_results()\n",
    "json_string = make_json(results)\n",
    "\n",
    "file = open(DATA_FILE_NAME, 'w')\n",
    "file.write(json_string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY = 'Developer'\n",
    "LOCATION = '' # location should be lowercase two letter state abbreviation (e.g. tx) or nothing for all states\n",
    "N_RESULTS = 1000\n",
    "DATA_FILE_NAME = 'linkedin_results_1000.json'\n",
    "\n",
    "def get_html_page(start):\n",
    "    request = 'https://www.linkedin.com/jobs/search?keywords='\n",
    "    query = QUERY.replace(' ', '%20') # Correct spaces\n",
    "    request += query\n",
    "    if len(LOCATION) > 0:\n",
    "        request += '&locationId=STATES.us.'\n",
    "        request += LOCATION\n",
    "    request += '&orig=JSERP&start='\n",
    "    request += str(start)\n",
    "    request += '&count=25&trk=jobs_jserp_pagination_'\n",
    "    request += str((start // 25) + 1) # Calculate page number\n",
    "    \n",
    "    return requests.get(request)\n",
    "\n",
    "def get_html_page_results(start):\n",
    "    results = []\n",
    "    # Request page until it doesn't redirect\n",
    "    while len(results) < 1:\n",
    "        html = get_html_page(start)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        results = soup.find_all('code', {'id' : 'decoratedJobPostingsModule'})\n",
    "    \n",
    "    result_json_string = results[0].string # all results come in one json object\n",
    "    json_data = json.loads(result_json_string) # get json data\n",
    "    \n",
    "    return json_data['elements'] # get search results\n",
    "\n",
    "def get_results():\n",
    "    results = []\n",
    "    current_start = 0\n",
    "    while len(results) < N_RESULTS:\n",
    "        results += get_html_page_results(current_start)\n",
    "        current_start = len(results)\n",
    "    return results\n",
    "    \n",
    "final_results = get_results()\n",
    "final_json_string = json.dumps({'results' : final_results}, sort_keys=True, indent=4) \n",
    "\n",
    "file = open(DATA_FILE_NAME, 'w')\n",
    "file.write(final_json_string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = IndeedClient(publisher=1234567890) # Your key goes here.\n",
    "\n",
    "results = [ ]\n",
    "i = 0\n",
    "pagenumber = 0\n",
    "for x in range(0, 40):\n",
    "    pagenumber += 1\n",
    "    params = {\n",
    "        'q': \"developer\",\n",
    "        'userip': \"\", # your ip goes here\n",
    "        'useragent': \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75 Safari/537.36\",\n",
    "        'start': i,\n",
    "        'limit': 25,\n",
    "        'radius': 25\n",
    "    }\n",
    "    i += 25\n",
    "    search_response = client.search(**params)\n",
    "    search_response = json.loads(json.dumps(search_response))\n",
    "\n",
    "    results += search_response[ 'results' ]\n",
    "\n",
    "json_string = json.dumps({'results': results}, sort_keys=True, indent=4)\n",
    "\n",
    "file = open('data.json', 'w')\n",
    "file.write(json_string)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Due to the lack of descriptions we had to find an alternate part of the data to explore. In the end we settled on exploring the locations of jobs and the titles of jobs. In order to analyze the locations of jobs we took from 1000 results from each job posting board. We then plotted the locations of these results onto a map and examined the locations of clusters as well as the density. Additionally we counted the number of times keywords appeared in the job titles. For example, we counted appearances of junior and senior to see the number of jobs available at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('linkedin_results_1000.json') as data_file:    \n",
    "    linkedin_json = json.load(data_file)\n",
    "    \n",
    "linkedin_results = linkedin_json['results']\n",
    "\n",
    "geolocator = Nominatim()\n",
    "linkedin_lons = []\n",
    "linkedin_lats = []\n",
    "for i in range(0, 1000):\n",
    "    location = geolocator.geocode(linkedin_results[i]['decoratedJobPosting']['cityState'])\n",
    "    linkedin_lons.append(location.longitude)\n",
    "    linkedin_lats.append(location.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('monster_results_1000.json') as data_file:\n",
    "    monster_json = json.load(data_file)\n",
    "\n",
    "monster_results = monster_json['results']\n",
    "\n",
    "geolocator = Nominatim()\n",
    "monster_lons = []\n",
    "monster_lats = []\n",
    "for i in range(0, 1000):\n",
    "    result = monster_results[i]['jobLocation']['address']['addressLocality'] + ', ' + monster_results[i]['jobLocation']['address']['addressRegion']\n",
    "    location = geolocator.geocode(result)\n",
    "    if location != None:\n",
    "        monster_lons.append(location.longitude)\n",
    "        monster_lats.append(location.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('indeed_results_1000.json') as data_file:\n",
    "    indeed_json = json.load(data_file)\n",
    "\n",
    "indeed_results = indeed_json['results']\n",
    "\n",
    "geolocator = Nominatim()\n",
    "indeed_lons = []\n",
    "indeed_lats = []\n",
    "for i in range(0, 1000):\n",
    "    location = geolocator.geocode(indeed_results[i]['formattedLocation'])\n",
    "    indeed_lons.append(location.longitude)\n",
    "    indeed_lats.append(location.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "themap = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection='lcc',lat_1=32,lat_2=45,lon_0=-95)\n",
    "themap.drawcoastlines()\n",
    "themap.drawcountries()\n",
    "themap.drawstates()\n",
    "themap.fillcontinents(color = 'gainsboro')\n",
    "themap.drawmapboundary(fill_color='steelblue')\n",
    "\n",
    "linkedin_x, linkedin_y = themap(linkedin_lons, linkedin_lats)\n",
    "      \n",
    "themap.plot(linkedin_x, linkedin_y, \n",
    "            'o',\n",
    "            color='Blue',\n",
    "            markersize=4\n",
    "            )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "themap = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection='lcc',lat_1=32,lat_2=45,lon_0=-95)\n",
    "themap.drawcoastlines()\n",
    "themap.drawcountries()\n",
    "themap.drawstates()\n",
    "themap.fillcontinents(color = 'gainsboro')\n",
    "themap.drawmapboundary(fill_color='steelblue')\n",
    "\n",
    "monster_x, monster_y = themap(monster_lons, monster_lats)\n",
    "\n",
    "themap.plot(monster_x, monster_y,\n",
    "           'o',\n",
    "            color = 'Purple',\n",
    "            markersize=4\n",
    "            )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "themap = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49, projection='lcc',lat_1=32,lat_2=45,lon_0=-95, resolution='f')\n",
    "themap.drawcoastlines()\n",
    "themap.drawcountries()\n",
    "themap.drawstates()\n",
    "themap.fillcontinents(color = 'gainsboro')\n",
    "themap.drawmapboundary(fill_color='steelblue')\n",
    "\n",
    "indeed_x, indeed_y = themap(indeed_lons, indeed_lats)\n",
    "\n",
    "themap.plot(indeed_x, indeed_y,\n",
    "           'o',\n",
    "            color = 'Green',\n",
    "            markersize=4\n",
    "            )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bokeh.core.state:Session output file 'monster_graph.html' already exists, will be overwritten.\n",
      "INFO:bokeh.core.state:Session output file 'indeed_graph.html' already exists, will be overwritten.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Monster</th>\n",
       "      <th>Indeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.Net</td>\n",
       "      <td>76</td>\n",
       "      <td>115</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C++</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C#</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javascript</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java</td>\n",
       "      <td>100</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Android</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Security</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Full Stack</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Front End</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Devops</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>133</td>\n",
       "      <td>120</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Architect</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Applications</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Programmer Analyst</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Network</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IT</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>189</td>\n",
       "      <td>173</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QA</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Intern</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Entry Level</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Associate</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mid Level</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior</td>\n",
       "      <td>128</td>\n",
       "      <td>95</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Principal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Staff</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lead</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Director</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title  LinkedIn  Monster  Indeed\n",
       "0                 .Net        76      115      33\n",
       "1                  C++        19        7       1\n",
       "2                   C#        27       30       9\n",
       "3           Javascript        25       35      20\n",
       "4                Java        100      149      28\n",
       "5              Android        26       17       6\n",
       "6             Security         1        1       0\n",
       "7           Full Stack        32       43      24\n",
       "8            Front End        43        6     107\n",
       "9               Devops         0        2       1\n",
       "10       Web Developer       133      120     300\n",
       "11           Architect         7       13       7\n",
       "12                Data        24       24      33\n",
       "13        Applications        21       42      22\n",
       "14  Programmer Analyst         4        0       0\n",
       "15             Network         4        7       1\n",
       "16              Mobile        33       17      11\n",
       "17                  IT        48       64      60\n",
       "18   Software Engineer       189      173     273\n",
       "19    Systems Engineer         2        1       1\n",
       "20                  QA         6        1      25\n",
       "21              Intern         8        3      49\n",
       "22         Entry Level         8        6      74\n",
       "23           Associate         6        0       8\n",
       "24           Mid Level         1        3       4\n",
       "25              Senior       128       95      16\n",
       "26           Principal         3        3       0\n",
       "27               Staff         5        2       1\n",
       "28                Lead        24       29       8\n",
       "29            Director         0        0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('linkedin_results_1000.json') as data_file:    \n",
    "    linkedin_json = json.load(data_file)\n",
    "\n",
    "linkedin_results = linkedin_json['results']\n",
    "\n",
    "linkedin_titles = []\n",
    "for i in range(0, len(linkedin_results)):\n",
    "    linkedin_titles.append(linkedin_results[i]['decoratedJobPosting']['jobPosting']['title'])\n",
    "    \n",
    "with open('monster_results_1000.json') as data_file:\n",
    "    monster_json = json.load(data_file)\n",
    "    \n",
    "monster_results = monster_json['results']\n",
    "\n",
    "monster_titles = []\n",
    "for i in range(0, len(monster_results)):\n",
    "    monster_titles.append(monster_results[i]['title'])\n",
    "    \n",
    "with open('indeed_results_1000.json') as data_file:\n",
    "    indeed_json = json.load(data_file)\n",
    "    \n",
    "indeed_results = indeed_json['results']\n",
    "\n",
    "indeed_titles = []\n",
    "for i in range(0, len(indeed_results)):\n",
    "    indeed_titles.append(indeed_results[i]['jobtitle'])\n",
    "    \n",
    "names = [\n",
    "    (\".Net\", \"\\.net\"),\n",
    "    (\"C++\", \"c\\+\\+\"),\n",
    "    (\"C#\", \"c\\#\"),\n",
    "    (\"Javascript\", \"javascript\"),\n",
    "    (\"Java \", \"java \"),\n",
    "    (\"Android\", \"android\"),\n",
    "    (\"Security\", \"security\"),\n",
    "    (\"Full Stack\", \"full stack\"),\n",
    "    (\"Front End\", \"front end\"),\n",
    "    (\"Devops\", \"devops\"),\n",
    "    (\"Web Developer\", \"web\"),\n",
    "    (\"Architect\", \"architect\"),\n",
    "    (\"Data\", \"data\"),\n",
    "    (\"Applications\", \"applications|(app )\"),\n",
    "    (\"Programmer Analyst\", \"programmer analyst\"),\n",
    "    (\"Network\", \"network\"),\n",
    "    (\"Mobile\", \"mobile\"),\n",
    "    (\"IT\", \"(it|(information (technology|systems)))\"),\n",
    "    (\"Software Engineer\", \"software (engineer|developer|development)\"),\n",
    "    (\"Systems Engineer\", \"systems engineer\"),\n",
    "    (\"QA\", \"test|(quality assurance|qa)\"),\n",
    "    (\"Intern\", \"Intern\"),\n",
    "    (\"Entry Level\", \"(new grad)|(entry level)\"),\n",
    "    (\"Associate\", \"associate\"),\n",
    "    (\"Mid Level\", \"mid level\"),\n",
    "    (\"Senior\", \"senior\"),\n",
    "    (\"Principal\", \"principal\"),\n",
    "    (\"Staff\", \"staff\"),\n",
    "    (\"Lead\", \"lead\"),\n",
    "    (\"Director\", \"director\"),\n",
    "]\n",
    "\n",
    "def get_counts(titles):\n",
    "    counts = []\n",
    "    for name in names:\n",
    "        count = 0\n",
    "        for title in titles:\n",
    "            if re.search(name[1], title, flags=re.IGNORECASE) is not None:\n",
    "                count += 1\n",
    "        counts.append(count)\n",
    "    return counts\n",
    "                \n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "formatted_names = []\n",
    "for name in names:\n",
    "    formatted_names.append(name[0])\n",
    "    \n",
    "dataframe['Title'] = pd.Series(formatted_names)\n",
    "dataframe['LinkedIn'] = pd.Series(get_counts(linkedin_titles))\n",
    "dataframe['Monster'] = pd.Series(get_counts(monster_titles))\n",
    "dataframe['Indeed'] = pd.Series(get_counts(indeed_titles))\n",
    "\n",
    "linkedin_graph = Bar(dataframe, 'Title', values='LinkedIn', legend=False)\n",
    "output_file(\"linkedin_graph.html\")\n",
    "show(linkedin_graph)\n",
    "monster_graph = Bar(dataframe, 'Title', values='Monster', legend=False)\n",
    "output_file(\"monster_graph.html\")\n",
    "show(monster_graph)\n",
    "indeed_graph = Bar(dataframe, 'Title', values='Indeed', legend=False)\n",
    "output_file(\"indeed_graph.html\")\n",
    "show(indeed_graph)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final Analysis\n",
    "\n",
    "#### Location Analysis\n",
    "\n",
    "From the analysis of the locations it is apparent that LinkedIn features the most locations. However, all three have similar clusters in obvious hotspots (Silicon Valley, Dallas, Washington D.C., etc.). Overall the analysis of locations did not reveal as much as we had hoped. Still, it is useful that if you are looking for jobs in non-standard locations you may want to use LinkedIn as your primary search board.\n",
    "\n",
    "#### Title Analysis\n",
    "\n",
    "From the analysis of the job titles several trends become apparent.\n",
    "1. Indeed is heavily weighted towards web development.\n",
    "2. Monster has the highest amount of Java and .Net jobs.\n",
    "3. LinkedIn has the most senior level jobs, and Indeed has the most entry level jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs489]",
   "language": "python",
   "name": "conda-env-cs489-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
